embed_buffer_t defaultConfig = {17616,
"# $Revision: 1.22 $  $Author: trey $  $Date: 2007/07/08 20:59:30 $\n"
"\n"
"# shortcuts for commonly used options\n"
"alias eval evaluate\n"
"alias bench benchmark\n"
"alias -d --debugLevel 1\n"
"alias -f --useFastModelParser 1\n"
"alias -i --evaluationTrialsPerEpoch\n"
"alias -l --lowerBoundRepresentation\n"
"alias -o --policyOutputFile\n"
"alias -p --terminateRegretBound\n"
"alias -s --searchStrategy\n"
"alias -t --terminateWallclockSeconds\n"
"alias -u --upperBoundRepresentation\n"
"\n"
"# command: The command to run: 'solve', 'benchmark', or 'evaluate'.\n"
"# Normally, this is set by the first command-line argument, not\n"
"# counting flags.  Thus you can write 'solve' instead of '--command solve'.\n"
"command none\n"
"\n"
"# simulatorModel: The problem model to use in simulation when evaluating\n"
"# a policy.  By default, the same model is passed to the planner, but\n"
"# you can give a different model to the planner using the plannerModel\n"
"# config field.  Normally, this is set by the second command-line argument,\n"
"# not counting flags. Thus you can write 'my.pomdp' instead of\n"
"# '--simulatorModel my.pomdp'.\n"
"simulatorModel none\n"
"\n"
"# searchStrategy: Specifies search strategy.  Valid choices are\n"
"# 'frtdp', 'hsvi', 'rtdp', 'lrtdp', 'hdp', and 'script'.  ('script'\n"
"# reads a fixed sequence of states to back up from input files;\n"
"# see the 'backupScriptInputDir' parameter below.)\n"
"searchStrategy frtdp\n"
"\n"
"# modelType: Specifies the type of planning model.  Valid choices are\n"
"# '-', 'pomdp', 'mdp', 'racetrack', and 'custom'.  '-' tells ZMDP to\n"
"# infer the model type from its filename extension. 'pomdp' means the\n"
"# model is in Tony Cassandra's POMDP file format.  'mdp' means the model\n"
"# is in Cassandra's MDP file format (a variant of the POMDP format in\n"
"# which observations are not specified).  'racetrack' means the model is\n"
"# from the racetrack MDP domain.  'custom' tells ZMDP to use the\n"
"# user-defined model you implement by editing src/mdps/CustomMDP.cc.\n"
"modelType -\n"
"\n"
"# lowerBoundRepresentation: Specifies how to represent the lower bound\n"
"# on the optimal value function.  Valid choices are '-', 'point', and\n"
"# 'maxPlanes'. '-' tells ZMDP to use the default representation for the\n"
"# given model type ('point' for MDP problems and 'maxPlanes' for POMDP\n"
"# problems).\n"
"lowerBoundRepresentation -\n"
"\n"
"# upperBoundRepresentation: Specifies how to represent the upper bound\n"
"# on the optimal value function.  Valid choices are '-', 'point', and\n"
"# 'sawtooth'. '-' tells ZMDP to use the default representation for the\n"
"# given model type ('point' for MDP problems and 'sawtooth' for POMDP\n"
"# problems).\n"
"upperBoundRepresentation -\n"
"\n"
"# maintainLowerBound: Specify '-', 0, or 1.  If 1, maintain a lower\n"
"# bound on the optimal value function during search.  If '-', maintain\n"
"# the lower bound only if it is required for the given search algorithm\n"
"# (it is required for 'frtdp' and 'hsvi').\n"
"maintainLowerBound -\n"
"\n"
"# maintainUpperBound: Specify 0 or 1.  If 1, maintain an upper bound\n"
"# on the optimal value function during search.  All the search strategies\n"
"# except 'script' require maintainUpperBound=1.\n"
"maintainUpperBound 1\n"
"\n"
"# policyOutputFile: Specifies where to write the output policy.  ZMDP\n"
"# outputs the current policy at the following times: (1) at each\n"
"# evaluation epoch [when using zmdp benchmark], and (2) whenever the run\n"
"# terminates for any reason (target regret bound reached, timeout, or\n"
"# ctrl-C user interrupt).  Note that policies can currently only be\n"
"# output if modelType='pomdp' and lowerBoundRepresentation='maxPlanes'.\n"
"# '-' tells ZMDP to write the policy to 'out.policy' if the zmdp solve\n"
"# front-end is used and disable policy output otherwise.  'none' tells\n"
"# ZMDP to disable policy output.\n"
"policyOutputFile -\n"
"\n"
"# useFastModelParser: Specify 0 or 1.  If value is 0, Tony Cassandra's\n"
"# canonical parser is used to parse POMDPs.  If value is 1, ZMDP's\n"
"# built-in POMDP parser is used.  ZMDP's parser is much faster for large\n"
"# problems but does not support all the constructs in Cassandra's POMDP\n"
"# specification language (for instance, states must be identified\n"
"# numerically rather than with string identifiers).  Most POMDPs in\n"
"# Cassandra's POMDP repository are not compatible with the fast parser\n"
"# as-is, but could be translated to the language subset it understands.\n"
"# See the RockSample problems for a compatible example.\n"
"useFastModelParser 0\n"
"\n"
"# terminateRegretBound: If set to a positive value, the solution\n"
"# algorithm will terminate when the regret of the current policy with\n"
"# respect to the optimal policy is bounded to the specified value.\n"
"# NOTE: This may not work as expected if only one-sided bounds are\n"
"# maintained, since the usual way ZMDP bounds regret is to calculate\n"
"# upperBound(b0) - lowerBound(b0).\n"
"terminateRegretBound 1e-3\n"
"\n"
"# terminateLowerBoundValue: If set to a value other than -999, the\n"
"# solution algorithm will terminate when lowerBound(b0) >=\n"
"# terminateLowerBoundValue.\n"
"# [zmdp benchmark only]\n"
"terminateLowerBoundValue -999\n"
"\n"
"# terminateUpperBoundValue: If set to a value other than -999, the\n"
"# solution algorithm will terminate when upperBound(b0) <=\n"
"# terminateUpperBoundValue.\n"
"# [zmdp benchmark only]\n"
"terminateUpperBoundValue -999\n"
"\n"
"# terminateWallclockSeconds: If set to a positive value, the solution\n"
"# algorithm will terminate after running for the specified amount of\n"
"# wallclock time.  The termination check excludes time spent outside the\n"
"# solution algorithm, e.g. reading model files and evaluating policies\n"
"# for benchmark purposes.  Also note that the termination check is only\n"
"# performed at the end of trials, so the reported final wallclock time\n"
"# will usually exceed the specified termination condition.\n"
"terminateWallclockSeconds -1\n"
"\n"
"# terminateNumBackups (integer): If set to a positive value, terminate\n"
"# after the specified number of backups have been performed by the\n"
"# heuristic search algorithm.  Note that the termination check is only\n"
"# performed at the end of trials, so the reported final number of backups\n"
"# will usually exceed the specified termination condition.\n"
"terminateNumBackups -1\n"
"\n"
"# debugLevel (integer): At higher debug levels ZMDP will output more\n"
"# verbose debugging messages.  Currently, only level 0 (normal level)\n"
"# and level 1 (extra debugging) are useful.\n"
"debugLevel 0\n"
"\n"
"# maxHorizon (integer): If set to a positive value, informs ZMDP that\n"
"# the system is guaranteed to enter a zero-reward absorbing state after\n"
"# at most the specified number of time steps.  This hint is used to\n"
"# calculate tighter initial bounds (currently only used for POMDP\n"
"# problems).  Note: If the problem is an undiscounted POMDP, you must\n"
"# specify a maxHorizon value.\n"
"maxHorizon -1\n"
"\n"
"# useWeakUpperBoundHeuristic: Specify 0 or 1.  If 1, avoid spending time\n"
"# generating a good upper bound heuristic.  This only applies to some\n"
"# problems and interpretation depends on the problem; e.g., sets h_U = 0\n"
"# for racetrack.\n"
"useWeakUpperBoundHeuristic 0\n"
"\n"
"# runTimeActionSelection: Specify '-', 'upper', or 'lower'.  Run-time\n"
"# (i.e., evaluation epoch time) action selection uses one-step lookahead\n"
"# with either the upper or lower bound based on what you specify.  '-'\n"
"# tells ZMDP to use the lower bound if it is available and fall back to\n"
"# the upper bound otherwise.\n"
"runTimeActionSelection -\n"
"\n"
"# evaluationTrialsPerEpoch: Specifies the number of simulation trials to\n"
"# run at each policy evaluation epoch.  The reported policy quality for\n"
"# the epoch is the mean reward achieved over the set of trials.\n"
"# [does not apply to zmdp solve]\n"
"evaluationTrialsPerEpoch 1000\n"
"\n"
"# evaluationMaxStepsPerTrial: If set to a positive value, specifies the\n"
"# maximum number of time steps to run each simulation trial when\n"
"# evaluating policy quality.  Note that ZMDP will automatically terminate\n"
"# a trial if the system enters a zero-reward absorbing state, so if\n"
"# your model guarantees this will happen in finite time you may find you\n"
"# don't need to set this parameter.\n"
"# [does not apply to zmdp solve]\n"
"evaluationMaxStepsPerTrial 251\n"
"\n"
"# evaluationFirstEpochWallclockSeconds: Specifies the amount of\n"
"# wallclock time to run the solution algorithm for before the first\n"
"# policy evaluation epoch.  Note: because the benchmark driver can only\n"
"# run evaluation epochs when the solution algorithm yields control, the\n"
"# actual epoch timing is not guaranteed to match what you specify.  The\n"
"# timing guarantees are that (1) the evaluation epoch will start *after*\n"
"# the time you specify, and (2) the actual elapsed wallclock time will\n"
"# be accurately logged in the benchmark output used for plotting.\n"
"# [zmdp benchmark only]\n"
"evaluationFirstEpochWallclockSeconds 1.0\n"
"\n"
"# evaluationEpochsPerMagnitude: Evaluation epoch timing is spaced\n"
"# logarithmically according to elapsed wallclock time.  This parameter\n"
"# specifies the number of epochs per order of magnitude in a log plot.\n"
"# For instance, if 3 is specified, there will be three epochs between 10\n"
"# and 100 seconds elapsed, three between 100 and 1000 seconds elapsed,\n"
"# etc.\n"
"# [zmdp benchmark only]\n"
"evaluationEpochsPerMagnitude 10\n"
"\n"
"# useEvaluationCache: If 1, use fancy techniques to speed up policy\n"
"# evaluation.  Techniques could include caching the policy and\n"
"# reweighting trajectories to reduce variance.\n"
"# [zmdp benchmark only]\n"
"useEvaluationCache 1\n"
"\n"
"# evaluationOutputFile: Specifies where to write results from policy\n"
"# evaluation.  The resulting file has one line per epoch.\n"
"# [zmdp benchmark only]\n"
"evaluationOutputFile inc.plot\n"
"\n"
"# boundsOutputFile: Specifies where to write data on bounds at the\n"
"# initial state. The resulting file has one line per top-level\n"
"# trial of the search algorithm.\n"
"# [zmdp benchmark only]\n"
"boundsOutputFile bounds.plot\n"
"\n"
"# simulationTraceOutputFile: Specifies where to write logs of simulator\n"
"# state/belief, actions selected, etc. during policy evaluation.  The\n"
"# resulting file has two lines per time step of simulation.\n"
"# [does not apply to zmdp solve]\n"
"simulationTraceOutputFile sim.plot\n"
"\n"
"# simulationTracesToLogPerEpoch (integer): If set to a non-negative\n"
"# value, specifies the number of simulation traces to log at each\n"
"# evaluation epoch.  If set to a negative value, all traces are logged\n"
"# (note: this can lead to very large log files!).\n"
"# [does not apply to zmdp solve]\n"
"simulationTracesToLogPerEpoch 1\n"
"\n"
"# scoresOutputFile: Specifies where to write a log of the rewards achieved\n"
"# in all simulation trials.  Each line in the log represents the total\n"
"# (discounted) reward achieved in a single simulation trial.\n"
"# [zmdp evaluate only]\n"
"scoresOutputFile scores.plot\n"
"\n"
"# useTimeWithoutHeuristic: Specify 0 or 1.  If 1, the wallclock times\n"
"# reported in zmdp benchmark performance logs will *not* include the time\n"
"# taken to generate initial bounds.  Instead, they will only include\n"
"# time spent in heuristic search trials.  This option allows you to\n"
"# eliminate one confounding factor in the timing when comparing\n"
"# different algorithms with the same initialization procedure.  Of\n"
"# course, you should not turn it on when comparing algorithms that use\n"
"# different initialization procedures.\n"
"useTimeWithoutHeuristic 1\n"
"\n"
"# useMaxPlanesMasking: Specify 0 or 1.  If 1, try to compress the\n"
"# maxPlanes lower bound representation by maintaining 'masked' alpha\n"
"# vectors.  When an alpha vector is calculated by a backup at a specific\n"
"# belief, ZMDP will retain only the entries of the alpha vector that\n"
"# correspond to non-zero entries of the belief.  The resulting alpha\n"
"# vector is not as widely useful, since it only applies to a submanifold\n"
"# of the belief simplex.  However, masking can provide massive\n"
"# advantages on sparse problems where masked alpha vectors are much\n"
"# easier to generate and consume much less memory.\n"
"useMaxPlanesMasking 1\n"
"\n"
"# useMaxPlanesSupportList: Specify 0 or 1.  useMaxPlanesSupportList=1\n"
"# requires useMaxPlanesMasking=1.  If 1, try to speed up maxPlanes value\n"
"# function queries by keeping a list of alpha vectors that 'support'\n"
"# each state in the sense that the state is part of the alpha vector's\n"
"# mask.  When the value for a belief is queried, the algorithm can restrict\n"
"# its consideration of planes to the support list for one of the non-zero\n"
"# entries of the belief, rather than considering all planes.\n"
"useMaxPlanesSupportList 1\n"
"\n"
"# useMaxPlanesCache: Specify 0 or 1.  If 1, enables a set of\n"
"# caching-related speedups in the maxPlanes lower bound.  A mapping from\n"
"# search graph nodes to most recent dominant planes is maintained, along\n"
"# with 'age' information about when nodes were updated and when planes\n"
"# were created.  This speeds up value function queries.\n"
"useMaxPlanesCache 1\n"
"\n"
"# useMaxPlanesExtraPruning: Specify 0 or 1. useMaxPlanesExtraPruning=1\n"
"# requires useMaxPlanesCache=1.  If 1, enables more aggressive pruning\n"
"# that deletes alpha vectors which are known not to be dominant at any\n"
"# belief that has been queried so far in the run.  If 0, only alpha\n"
"# vectors that are pointwise dominated (i.e., dominated by a single other\n"
"# alpha vector throughout the belief simplex) will be pruned.\n"
"useMaxPlanesExtraPruning 1\n"
"\n"
"# useSawtoothSupportList: Specify 0 or 1.  If 1, try to speed up\n"
"# sawtooth value function queries by keeping a list of upper bound\n"
"# belief points that 'support' each state in the sense that the belief's\n"
"# entry for the state is non-zero.  When the value for a belief is\n"
"# queried, the algorithm restricts its consideration of planes to the\n"
"# support list for one of the non-zero entries of the belief, rather\n"
"# than considering all planes.  To relate this to the maxPlanes\n"
"# parameters, turning on useSawtoothSupportList=1 is similar to to\n"
"# turning on useMaxPlanesMasking=1 and useMaxPlanesSupportList=1.  For\n"
"# the sawtooth representation, turning on masking without support lists\n"
"# doesn't make much sense; thus we don't provide a separate masking\n"
"# parameter.\n"
"useSawtoothSupportList 1\n"
"\n"
"# useLogBackups: Specify 0 or 1.  If 1, generate the logs specified\n"
"# by the stateIndexOutputFile and backupsOutputFile parameters.\n"
"# [zmdp benchmark only]\n"
"useLogBackups 0\n"
"\n"
"# stateIndexOutputFile: Specifies where to write an index of states (or\n"
"# POMDP beliefs) that are referenced in other log files.  The index\n"
"# file provides a unique numeric identifier for every state of interest.\n"
"# [zmdp benchmark only]\n"
"stateIndexOutputFile stateIndex.log\n"
"\n"
"# backupsOutputFile: Specifies where to write a log of state (or POMDP\n"
"# belief) backups.  The log is in chronological order and contains one\n"
"# line per backup made.  The line lists the index number (from the\n"
"# stateIndexOutputFile) for the backed up state.\n"
"# [zmdp benchmark only]\n"
"backupsOutputFile backups.log\n"
"\n"
"# backupScriptInputDir: If searchStrategy='script', ZMDP will read a\n"
"# sequence of states to back up from the given directory.  Specifically,\n"
"# ZMDP tries to read the sequence from files in the directory with the\n"
"# names given in the 'stateIndexOutputFile' and 'backupsOutputFile'\n"
"# parameters.  This allows you to repeat the exact sequence of updates\n"
"# from an earlier run, even if you are using different parameters that\n"
"# would normally affect which states are updated (e.g. a different value\n"
"# function representation).\n"
"# [zmdp benchmark only]\n"
"backupScriptInputDir none\n"
"\n"
"# boundValuesOutputFile: Specifies where to write a list of state\n"
"# (or POMDP belief) bound values.  The list is written if either\n"
"# searchStrategy='script' or useLogBackups=1.  It includes lower and\n"
"# upper bound values for the states in the index file.\n"
"boundValuesOutputFile boundValues.log\n"
"\n"
"# qValuesOutputFile: If set to a value other than 'none', ZMDP will\n"
"# write a list of bounds on Q values for all state/action pairs to the\n"
"# specified file.  The states are specified in the file using the\n"
"# indices defined in the stateIndexOutputFile.\n"
"qValuesOutputFile none\n"
"\n"
"# customMDPNumStates: This parameter is provided as an example of how\n"
"# to pass run-time parameters to a custom MDP you create by modifying\n"
"# the CustomMDP class in src/mdps/CustomMDP.cc.  The problem\n"
"# in the example implementation of CustomMDP has a variable number of\n"
"# states determined by this parameter.  You can override the config\n"
"# file value from the command-line, with e.g. '--customMDPNumStates 10'.\n"
"customMDPNumStates 5\n"
"\n"
"# storageOutputFile: Specifies where to write a log of storage space\n"
"# used throughout the ZMDP run.\n"
"# [zmdp benchmark only]\n"
"storageOutputFile none\n"
"\n"
"# policyInputFile: Specifies the name of the file to read in the policy\n"
"# from.  Note: For some policy types (for instance, 'lspath' and 'lsblind'),\n"
"# the policy is generated during initialization of the evaluator, so that\n"
"# no policyInputFile is needed.\n"
"# [zmdp evaluate only]\n"
"policyInputFile out.policy\n"
"\n"
"# policyType: Specifies the type of policy to use during evaluation.\n"
"# Options include 'maxPlanes', 'cassandraAlpha', 'lspath', and\n"
"# 'lsblind'.  With the 'maxPlanes' and 'cassandraAlpha' policy types,\n"
"# you must specify a policy file for zmdp evaluate to read in.  The\n"
"# 'lspath' and 'lsblind' policy types are heuristics that work only\n"
"# with LifeSurvey problems.\n"
"# [zmdp evaluate only]\n"
"policyType maxPlanes\n"
"\n"
"# plannerModel: The problem model to give to the planner (or to use when\n"
"# interpreting a ZMDP policy).  If the value is '-', the plannerModel is\n"
"# set to be the same as the simulatorModel.  When evaluating a ZMDP\n"
"# policy, you must specify the same plannerModel that was used when the\n"
"# policy was generated in order for it to be executed properly.\n"
"plannerModel -\n"
"\n"
"# customModel: Certain types of policies ('lspath' and 'lsblind')\n"
"# require additional information about the structure of the planning\n"
"# model that is not included in the Cassandra-format file.  This\n"
"# field specifies the file where that information is found\n"
"# (for example, \"ltv1.lifeSurvey\").\n"
"# [zmdp evaluate only]\n"
"customModel none\n"
};
